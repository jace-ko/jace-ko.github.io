<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tech 2019 on My Site</title>
    <link>https://mason-ko.github.io/posts/tech/2019/</link>
    <description>Recent content in Tech 2019 on My Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 17 May 2019 11:03:00 +0900</lastBuildDate><atom:link href="https://mason-ko.github.io/posts/tech/2019/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Docker Debug With Rider</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-05-17-docker-debug-with-rider/</link>
      <pubDate>Fri, 17 May 2019 11:03:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-05-17-docker-debug-with-rider/</guid>
      <description>![My helpful screenshot]({{ &amp;ldquo;/assets/20190517/capture1.png&amp;rdquo; | absolute_url }}) ![My helpful screenshot]({{ &amp;ldquo;/assets/20190517/capture2.png&amp;rdquo; | absolute_url }})
{% highlight Kconfig %} FROM microsoft/dotnet:2.1-aspnetcore-runtime as base
FROM microsoft/dotnet:2.1-sdk as build WORKDIR /src
COPY ConsoleApp1/ConsoleApp1.csproj ConsoleApp1/
RUN dotnet restore ConsoleApp1/ConsoleApp1.csproj
COPY . . WORKDIR /src/ConsoleApp1
RUN dotnet build ConsoleApp1.csproj -c Release -o /app
FROM build as publish RUN dotnet publish ConsoleApp1.csproj -c Release -o /app
FROM base AS final WORKDIR /app COPY &amp;ndash;from=publish /app .</description>
    </item>
    
    <item>
      <title>Cassandra Commit log 충돌로 인한 Restart 불가 현상</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-04-08-cassandra-commit-log-error/</link>
      <pubDate>Mon, 08 Apr 2019 17:26:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-04-08-cassandra-commit-log-error/</guid>
      <description>Cassandra가 비정상 종료됬을때 발생.
Mount된 Commit log 폴더의 내용을 삭제 or ignorereplayerrors 를 true로 줌 {% highlight Kconfig %} Environment
 JVM_OPTS : &amp;ldquo;-Dcassandra.commitlog.ignorereplayerrors=true&amp;rdquo; {% endhighlight %}  </description>
    </item>
    
    <item>
      <title>Redis Warning 해결</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-04-08-redis-warning/</link>
      <pubDate>Mon, 08 Apr 2019 11:26:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-04-08-redis-warning/</guid>
      <description>Host PC에서 실행
{% highlight Kconfig %} sudo sysctl vm.overcommit_memory=1
#재부팅시 적용되려면 vi /etc/sysctl.conf
추가 net.core.somaxconn=1024 {% endhighlight %}
Host PC에서 실행
{% highlight Kconfig %} echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled
#재부팅시 적용되려면 vi /etc/rc.local
추가 echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled exit 0 {% endhighlight %}
Docker Compose yaml에 내용 추가 ( 65535 까지 가능 ) sysctls 은 docker compose version 2.1 이상부터 가능함을 확인
{% highlight Kconfig %} sysctls:
 net.core.somaxconn=1024 {% endhighlight %}  </description>
    </item>
    
    <item>
      <title>Redis Cluster</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-20-redis-cluster/</link>
      <pubDate>Wed, 20 Mar 2019 10:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-20-redis-cluster/</guid>
      <description>docker-compose.yaml
{% highlight Kconfig %} version: &amp;ldquo;3.1&amp;rdquo; services: redis-master-1: image: redis:5.0.2-alpine ports: - 7000:7000 command: sh -c &amp;ldquo;redis-server &amp;ndash;port 7000 &amp;ndash;cluster-enabled yes &amp;ndash;cluster-config-file nodes.conf &amp;ndash;cluster-node-timeout 5000&amp;rdquo; networks: redisnet: ipv4_address: 10.0.0.2 redis-master-2: image: redis:5.0.2-alpine ports: - 7001:7001 command: sh -c &amp;ldquo;redis-server &amp;ndash;port 7001 &amp;ndash;cluster-enabled yes &amp;ndash;cluster-config-file nodes.conf &amp;ndash;cluster-node-timeout 5000&amp;rdquo; networks: redisnet: ipv4_address: 10.0.0.3 depends_on: - redis-master-1 redis-master-3: image: redis:5.0.2-alpine ports: - 7002:7002 command: sh -c &amp;ldquo;redis-server &amp;ndash;port 7002 &amp;ndash;cluster-enabled yes &amp;ndash;cluster-config-file nodes.</description>
    </item>
    
    <item>
      <title>Spark Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-05-spark-cluster/</link>
      <pubDate>Tue, 05 Mar 2019 14:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-05-spark-cluster/</guid>
      <description>docker-compose.yaml
{% highlight Kconfig %} version: &amp;ldquo;3.0&amp;rdquo; services: spark-master: image: bde2020/spark-master:2.3.2-hadoop2.7 container_name: spark-master ports: - &amp;ldquo;8083:8083&amp;rdquo; - &amp;ldquo;7077:7077&amp;rdquo; environment: - INIT_DAEMON_STEP=setup_spark - &amp;ldquo;constraint:node==&amp;rdquo; spark-worker-1: image: bde2020/spark-worker:2.3.2-hadoop2.7 container_name: spark-worker-1 depends_on: - spark-master ports: - &amp;ldquo;8081:8081&amp;rdquo; environment: - &amp;ldquo;SPARK_MASTER=spark://spark-master:7077&amp;rdquo; - &amp;ldquo;constraint:node==&amp;rdquo; spark-worker-2: image: bde2020/spark-worker:2.3.2-hadoop2.7 container_name: spark-worker-2 depends_on: - spark-master ports: - &amp;ldquo;8082:8082&amp;rdquo; environment: - &amp;ldquo;SPARK_MASTER=spark://spark-master:7077&amp;rdquo; - &amp;ldquo;constraint:node==&amp;rdquo; {% endhighlight %}
Spark Master - Worker </description>
    </item>
    
    <item>
      <title>Zeppelin Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-05-zeppelin/</link>
      <pubDate>Tue, 05 Mar 2019 14:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-05-zeppelin/</guid>
      <description>docker-compose.yaml
{% highlight Kconfig %} version: &amp;ldquo;3.0&amp;rdquo; services: zeppelin1: image: apache/zeppelin:0.8.0 container_name: docker_zeppelin_1 ports: - &amp;ldquo;8080:8080&amp;rdquo; {% endhighlight %}
spark가 로컬이 아닐 경우에는 spark-submit을 통해 사용하기 때문에 spark가 zeppelin 내부에 설치가 되어 있어야 함 up -d 이후 Docker Container안에서 Spark를 Download( wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz ) {% highlight Kconfig %} docker exec -it docker_zepplein_1 bash wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz tar -xvf spark-2.3.2-bin-hadoop2.7.tgz mv spark-2.3.2-bin-hadoop2.7 /spark {% endhighlight %}
Interpreters에서 Create Interpreter group 을 Spark로 설정 Properties에 Spark 관련 Property를 추가  SPARK_HOME: /spark  SPARK_SUBMIT_OPTIONS: &amp;ndash;packages datastax:spark-cassandra-connector:2.</description>
    </item>
    
    <item>
      <title>Kafka Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-02-15-kafka-cluster/</link>
      <pubDate>Fri, 15 Feb 2019 13:42:46 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-02-15-kafka-cluster/</guid>
      <description>docker-compose.yaml
{% highlight Kconfig %} version: &amp;lsquo;2.1&amp;rsquo;
services: zoo1: image: zookeeper:3.4.9 hostname: zoo1 ports: - &amp;ldquo;2181:2181&amp;rdquo; container_name: docker_zoo_1 environment: ZOO_MY_ID: 1 ZOO_PORT: 2181 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper:3.4.9 hostname: zoo2 ports: - &amp;ldquo;2182:2182&amp;rdquo; container_name: docker_zoo_2 environment: ZOO_MY_ID: 2 ZOO_PORT: 2182 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper:3.4.9 hostname: zoo3 ports: - &amp;ldquo;2183:2183&amp;rdquo; container_name: docker_zoo_3 environment: ZOO_MY_ID: 3 ZOO_PORT: 2183 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888
kafka1: image: confluentinc/cp-kafka:5.0.0 hostname: kafka1 ports: - &amp;ldquo;9092:9092&amp;rdquo; container_name: docker_kafka_1 environment: KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-192.</description>
    </item>
    
    <item>
      <title>Cassandra Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-01-21-cassandra-cluster/</link>
      <pubDate>Mon, 21 Jan 2019 11:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-01-21-cassandra-cluster/</guid>
      <description>docker-compose.yaml
{% highlight Kconfig %} version: &amp;lsquo;2&amp;rsquo; services: cassandra1: image: cassandra ports: - 7000:7000 - 7001:7001 - 9160:9160 - 9042:9042 environment: CASSANDRA_BROADCAST_ADDRESS: &amp;ldquo;10.5.0.10&amp;rdquo; CASSANDRA_SEEDS: &amp;ldquo;10.5.0.10&amp;rdquo; CASSANDRA_CLUSTER_NAME: &amp;ldquo;Test Cluster&amp;rdquo; CASSANDRA_DC: &amp;ldquo;DC1&amp;rdquo; CASSANDRA_RACK: &amp;ldquo;RAC1&amp;rdquo; CASSANDRA_ENDPOINT_SNITCH: &amp;ldquo;GossipingPropertyFileSnitch&amp;rdquo; CASSANDRA_START_RPC: &amp;ldquo;true&amp;rdquo; hostname: cassandra1 container_name: docker_cassandra_1 logging: driver: json-file options: max-size: 50m networks: cassnw: ipv4_address: 10.5.0.10 cassandra2: image: cassandra environment: CASSANDRA_BROADCAST_ADDRESS: &amp;ldquo;10.5.0.10&amp;rdquo; CASSANDRA_SEEDS: &amp;ldquo;10.5.0.10&amp;rdquo; CASSANDRA_CLUSTER_NAME: &amp;ldquo;Test Cluster&amp;rdquo; CASSANDRA_DC: &amp;ldquo;DC1&amp;rdquo; CASSANDRA_RACK: &amp;ldquo;RAC1&amp;rdquo; CASSANDRA_ENDPOINT_SNITCH: &amp;ldquo;GossipingPropertyFileSnitch&amp;rdquo; CASSANDRA_START_RPC: &amp;ldquo;true&amp;rdquo; hostname: cassandra2 container_name: docker_cassandra_2 logging: driver: json-file options: max-size: 50m networks: cassnw: ipv4_address: 10.</description>
    </item>
    
  </channel>
</rss>
