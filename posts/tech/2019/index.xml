<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tech 2019 on My Site</title>
    <link>https://mason-ko.github.io/posts/tech/2019/</link>
    <description>Recent content in Tech 2019 on My Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 17 May 2019 11:03:00 +0900</lastBuildDate><atom:link href="https://mason-ko.github.io/posts/tech/2019/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Docker Debug With Rider</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-05-17-docker-debug-with-rider/</link>
      <pubDate>Fri, 17 May 2019 11:03:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-05-17-docker-debug-with-rider/</guid>
      <description>1. Rider에서 Docker 사용 ![My helpful screenshot]({{ &amp;ldquo;/assets/20190517/capture1.png&amp;rdquo; | absolute_url }}) ![My helpful screenshot]({{ &amp;ldquo;/assets/20190517/capture2.png&amp;rdquo; | absolute_url }})
FROM microsoft/dotnet:2.1-aspnetcore-runtime as baseFROM microsoft/dotnet:2.1-sdk as buildWORKDIR /srcCOPY ConsoleApp1/ConsoleApp1.csproj ConsoleApp1/RUN dotnet restore ConsoleApp1/ConsoleApp1.csprojCOPY . .WORKDIR /src/ConsoleApp1RUN dotnet build ConsoleApp1.csproj -c Release -o /appFROM build as publishRUN dotnet publish ConsoleApp1.csproj -c Release -o /appFROM base AS finalWORKDIR /appCOPY --from=publish /app .ENTRYPOINT [&amp;quot;dotnet&amp;quot;, &amp;quot;ConsoleApp1.</description>
    </item>
    
    <item>
      <title>Cassandra Commit log 충돌로 인한 Restart 불가 현상</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-04-08-cassandra-commit-log-error/</link>
      <pubDate>Mon, 08 Apr 2019 17:26:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-04-08-cassandra-commit-log-error/</guid>
      <description>원인 Cassandra가 비정상 종료됬을때 발생.
해결방안 Mount된 Commit log 폴더의 내용을 삭제
or
ignorereplayerrors 를 true로 줌
Environment- JVM_OPTS : &amp;quot;-Dcassandra.commitlog.ignorereplayerrors=true&amp;quot;참고 cassandra CrashLooping due to invalid commit log</description>
    </item>
    
    <item>
      <title>Redis Warning 해결</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-04-08-redis-warning/</link>
      <pubDate>Mon, 08 Apr 2019 11:26:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-04-08-redis-warning/</guid>
      <description>1. overcommit_memory Host PC에서 실행
sudo sysctl vm.overcommit_memory=1#재부팅시 적용되려면vi /etc/sysctl.conf# 추가net.core.somaxconn=10242. THP Disable Host PC에서 실행
echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled#재부팅시 적용되려면vi /etc/rc.local# 추가echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabledexit 03. TCP Backlog Docker Compose yaml에 내용 추가 ( 65535 까지 가능 )
sysctls 은 docker compose version 2.1 이상부터 가능함을 확인
sysctls:- net.core.somaxconn=1024참고 Redis 설치 후 Warning 제거하기
Docker Docs</description>
    </item>
    
    <item>
      <title>Redis Cluster</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-20-redis-cluster/</link>
      <pubDate>Wed, 20 Mar 2019 10:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-20-redis-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &amp;quot;3.1&amp;quot;services:redis-master-1:image: redis:5.0.2-alpineports:- 7000:7000command: sh -c &amp;quot;redis-server --port 7000 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000&amp;quot;networks:redisnet:ipv4_address: 10.0.0.2redis-master-2:image: redis:5.0.2-alpineports:- 7001:7001command: sh -c &amp;quot;redis-server --port 7001 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000&amp;quot;networks:redisnet:ipv4_address: 10.0.0.3depends_on:- redis-master-1 redis-master-3:image: redis:5.0.2-alpineports:- 7002:7002command: sh -c &amp;quot;redis-server --port 7002 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000&amp;quot;networks:redisnet:ipv4_address: 10.</description>
    </item>
    
    <item>
      <title>Spark Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-05-spark-cluster/</link>
      <pubDate>Tue, 05 Mar 2019 14:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-05-spark-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &amp;quot;3.0&amp;quot;services:spark-master:image: bde2020/spark-master:2.3.2-hadoop2.7container_name: spark-masterports:- &amp;quot;8083:8083&amp;quot;- &amp;quot;7077:7077&amp;quot;environment:- INIT_DAEMON_STEP=setup_spark- &amp;quot;constraint:node==&amp;lt;yourmasternode&amp;gt;&amp;quot;spark-worker-1:image: bde2020/spark-worker:2.3.2-hadoop2.7container_name: spark-worker-1depends_on:- spark-masterports:- &amp;quot;8081:8081&amp;quot;environment:- &amp;quot;SPARK_MASTER=spark://spark-master:7077&amp;quot;- &amp;quot;constraint:node==&amp;lt;yourmasternode&amp;gt;&amp;quot;spark-worker-2:image: bde2020/spark-worker:2.3.2-hadoop2.7container_name: spark-worker-2depends_on:- spark-masterports:- &amp;quot;8082:8082&amp;quot;environment:- &amp;quot;SPARK_MASTER=spark://spark-master:7077&amp;quot;- &amp;quot;constraint:node==&amp;lt;yourworkernode&amp;gt;&amp;quot;Info Spark Master - Worker</description>
    </item>
    
    <item>
      <title>Zeppelin Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-05-zeppelin/</link>
      <pubDate>Tue, 05 Mar 2019 14:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-05-zeppelin/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &amp;quot;3.0&amp;quot;services:zeppelin1:image: apache/zeppelin:0.8.0container_name: docker_zeppelin_1ports:- &amp;quot;8080:8080&amp;quot;Info spark가 로컬이 아닐 경우에는 spark-submit을 통해 사용하기 때문에
spark가 zeppelin 내부에 설치가 되어 있어야 함
up -d 이후
Docker Container안에서 Spark를 Download( wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz )
docker exec -it docker_zepplein_1 bashwget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgztar -xvf spark-2.3.2-bin-hadoop2.7.tgzmv spark-2.3.2-bin-hadoop2.7 /sparkInterpreters에서 Create
Interpreter group 을 Spark로 설정 Properties에 Spark 관련 Property를 추가
 SPARK_HOME: /spark SPARK_SUBMIT_OPTIONS: &amp;ndash;packages datastax:spark-cassandra-connector:2.</description>
    </item>
    
    <item>
      <title>Kafka Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-02-15-kafka-cluster/</link>
      <pubDate>Fri, 15 Feb 2019 13:42:46 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-02-15-kafka-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &#39;2.1&#39;services:zoo1:image: zookeeper:3.4.9hostname: zoo1ports:- &amp;quot;2181:2181&amp;quot;container_name: docker_zoo_1environment:ZOO_MY_ID: 1ZOO_PORT: 2181ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888zoo2:image: zookeeper:3.4.9hostname: zoo2ports:- &amp;quot;2182:2182&amp;quot;container_name: docker_zoo_2environment:ZOO_MY_ID: 2ZOO_PORT: 2182ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888zoo3:image: zookeeper:3.4.9hostname: zoo3ports:- &amp;quot;2183:2183&amp;quot;container_name: docker_zoo_3environment:ZOO_MY_ID: 3ZOO_PORT: 2183ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888kafka1:image: confluentinc/cp-kafka:5.0.0hostname: kafka1ports:- &amp;quot;9092:9092&amp;quot;container_name: docker_kafka_1environment:KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-192.</description>
    </item>
    
    <item>
      <title>Cassandra Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-01-21-cassandra-cluster/</link>
      <pubDate>Mon, 21 Jan 2019 11:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-01-21-cassandra-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &#39;2&#39;services:cassandra1:image: cassandraports:- 7000:7000- 7001:7001- 9160:9160- 9042:9042environment:CASSANDRA_BROADCAST_ADDRESS: &amp;quot;10.5.0.10&amp;quot;CASSANDRA_SEEDS: &amp;quot;10.5.0.10&amp;quot;CASSANDRA_CLUSTER_NAME: &amp;quot;Test Cluster&amp;quot;CASSANDRA_DC: &amp;quot;DC1&amp;quot;CASSANDRA_RACK: &amp;quot;RAC1&amp;quot;CASSANDRA_ENDPOINT_SNITCH: &amp;quot;GossipingPropertyFileSnitch&amp;quot;CASSANDRA_START_RPC: &amp;quot;true&amp;quot;hostname: cassandra1container_name: docker_cassandra_1logging:driver: json-fileoptions:max-size: 50mnetworks:cassnw:ipv4_address: 10.5.0.10cassandra2:image: cassandraenvironment:CASSANDRA_BROADCAST_ADDRESS: &amp;quot;10.5.0.10&amp;quot;CASSANDRA_SEEDS: &amp;quot;10.5.0.10&amp;quot;CASSANDRA_CLUSTER_NAME: &amp;quot;Test Cluster&amp;quot;CASSANDRA_DC: &amp;quot;DC1&amp;quot;CASSANDRA_RACK: &amp;quot;RAC1&amp;quot;CASSANDRA_ENDPOINT_SNITCH: &amp;quot;GossipingPropertyFileSnitch&amp;quot;CASSANDRA_START_RPC: &amp;quot;true&amp;quot;hostname: cassandra2container_name: docker_cassandra_2logging:driver: json-fileoptions:max-size: 50mnetworks:cassnw:ipv4_address: 10.</description>
    </item>
    
  </channel>
</rss>
