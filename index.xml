<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My Site</title>
    <link>https://mason-ko.github.io/</link>
    <description>Recent content on My Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 16 Dec 2020 19:32:00 +0900</lastBuildDate><atom:link href="https://mason-ko.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>gRPC Gateway 를 사용하여 gin 에 띄웠을때 Marshaler 커스텀</title>
      <link>https://mason-ko.github.io/posts/tech/2020/2020-12-16-custom-mashaler-grpc-gateway/</link>
      <pubDate>Wed, 16 Dec 2020 19:32:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2020/2020-12-16-custom-mashaler-grpc-gateway/</guid>
      <description>Custom Mashlaer 생성 type myMarshaler struct { JSONPb *runtime.JSONPb } func NewMyMarshaler() runtime.ServeMuxOption { m := myMarshaler{ JSONPb: &amp;amp;runtime.JSONPb{OrigName: true, EmitDefaults: true}, } return runtime.WithMarshalerOption(runtime.MIMEWildcard, m) }  JSONPb interface 구현 func (m customMarshaler) Marshal(v interface{}) ([]byte, error) { return m.JSONPb.Marshal(v) } func (m myMarshaler) Unmarshal(data []byte, v interface{}) error { return m.JSONPb.Unmarshal(data, v) } func (m myMarshaler) NewDecoder(r io.Reader) runtime.Decoder { return m.JSONPb.NewDecoder(r) } func (m myMarshaler) NewEncoder(w io.Writer) runtime.</description>
    </item>
    
    <item>
      <title>Docker Debug With Rider</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-05-17-docker-debug-with-rider/</link>
      <pubDate>Fri, 17 May 2019 11:03:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-05-17-docker-debug-with-rider/</guid>
      <description>1. Rider에서 Docker 사용 ![My helpful screenshot]({{ &amp;ldquo;/assets/20190517/capture1.png&amp;rdquo; | absolute_url }}) ![My helpful screenshot]({{ &amp;ldquo;/assets/20190517/capture2.png&amp;rdquo; | absolute_url }})
FROM microsoft/dotnet:2.1-aspnetcore-runtime as base FROM microsoft/dotnet:2.1-sdk as build WORKDIR /src COPY ConsoleApp1/ConsoleApp1.csproj ConsoleApp1/ RUN dotnet restore ConsoleApp1/ConsoleApp1.csproj COPY . . WORKDIR /src/ConsoleApp1 RUN dotnet build ConsoleApp1.csproj -c Release -o /app FROM build as publish RUN dotnet publish ConsoleApp1.csproj -c Release -o /app FROM base AS final WORKDIR /app COPY --from=publish /app . ENTRYPOINT [&amp;quot;dotnet&amp;quot;, &amp;quot;ConsoleApp1.</description>
    </item>
    
    <item>
      <title>Cassandra Commit log 충돌로 인한 Restart 불가 현상</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-04-08-cassandra-commit-log-error/</link>
      <pubDate>Mon, 08 Apr 2019 17:26:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-04-08-cassandra-commit-log-error/</guid>
      <description>원인 Cassandra가 비정상 종료됬을때 발생.
해결방안 Mount된 Commit log 폴더의 내용을 삭제
or
ignorereplayerrors 를 true로 줌
Environment - JVM_OPTS : &amp;quot;-Dcassandra.commitlog.ignorereplayerrors=true&amp;quot; 참고 cassandra CrashLooping due to invalid commit log</description>
    </item>
    
    <item>
      <title>Redis Warning 해결</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-04-08-redis-warning/</link>
      <pubDate>Mon, 08 Apr 2019 11:26:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-04-08-redis-warning/</guid>
      <description>1. overcommit_memory Host PC에서 실행
sudo sysctl vm.overcommit_memory=1 #재부팅시 적용되려면 vi /etc/sysctl.conf # 추가 net.core.somaxconn=1024 2. THP Disable Host PC에서 실행
echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled #재부팅시 적용되려면 vi /etc/rc.local # 추가 echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled exit 0 3. TCP Backlog Docker Compose yaml에 내용 추가 ( 65535 까지 가능 )
sysctls 은 docker compose version 2.1 이상부터 가능함을 확인
sysctls: - net.core.somaxconn=1024 참고 Redis 설치 후 Warning 제거하기
Docker Docs</description>
    </item>
    
    <item>
      <title>Redis Cluster</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-20-redis-cluster/</link>
      <pubDate>Wed, 20 Mar 2019 10:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-20-redis-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &amp;quot;3.1&amp;quot; services: redis-master-1: image: redis:5.0.2-alpine ports: - 7000:7000 command: sh -c &amp;quot;redis-server --port 7000 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000&amp;quot; networks: redisnet: ipv4_address: 10.0.0.2 redis-master-2: image: redis:5.0.2-alpine ports: - 7001:7001 command: sh -c &amp;quot;redis-server --port 7001 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000&amp;quot; networks: redisnet: ipv4_address: 10.0.0.3 depends_on: - redis-master-1 redis-master-3: image: redis:5.0.2-alpine ports: - 7002:7002 command: sh -c &amp;quot;redis-server --port 7002 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000&amp;quot; networks: redisnet: ipv4_address: 10.</description>
    </item>
    
    <item>
      <title>Spark Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-05-spark-cluster/</link>
      <pubDate>Tue, 05 Mar 2019 14:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-05-spark-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &amp;quot;3.0&amp;quot; services: spark-master: image: bde2020/spark-master:2.3.2-hadoop2.7 container_name: spark-master ports: - &amp;quot;8083:8083&amp;quot; - &amp;quot;7077:7077&amp;quot; environment: - INIT_DAEMON_STEP=setup_spark - &amp;quot;constraint:node==&amp;lt;yourmasternode&amp;gt;&amp;quot; spark-worker-1: image: bde2020/spark-worker:2.3.2-hadoop2.7 container_name: spark-worker-1 depends_on: - spark-master ports: - &amp;quot;8081:8081&amp;quot; environment: - &amp;quot;SPARK_MASTER=spark://spark-master:7077&amp;quot; - &amp;quot;constraint:node==&amp;lt;yourmasternode&amp;gt;&amp;quot; spark-worker-2: image: bde2020/spark-worker:2.3.2-hadoop2.7 container_name: spark-worker-2 depends_on: - spark-master ports: - &amp;quot;8082:8082&amp;quot; environment: - &amp;quot;SPARK_MASTER=spark://spark-master:7077&amp;quot; - &amp;quot;constraint:node==&amp;lt;yourworkernode&amp;gt;&amp;quot; Info Spark Master - Worker</description>
    </item>
    
    <item>
      <title>Zeppelin Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-03-05-zeppelin/</link>
      <pubDate>Tue, 05 Mar 2019 14:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-03-05-zeppelin/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &amp;quot;3.0&amp;quot; services: zeppelin1: image: apache/zeppelin:0.8.0 container_name: docker_zeppelin_1 ports: - &amp;quot;8080:8080&amp;quot; Info spark가 로컬이 아닐 경우에는 spark-submit을 통해 사용하기 때문에
spark가 zeppelin 내부에 설치가 되어 있어야 함
up -d 이후
Docker Container안에서 Spark를 Download( wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz )
docker exec -it docker_zepplein_1 bash wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz tar -xvf spark-2.3.2-bin-hadoop2.7.tgz mv spark-2.3.2-bin-hadoop2.7 /spark Interpreters에서 Create
Interpreter group 을 Spark로 설정 Properties에 Spark 관련 Property를 추가
 SPARK_HOME: /spark SPARK_SUBMIT_OPTIONS: &amp;ndash;packages datastax:spark-cassandra-connector:2.</description>
    </item>
    
    <item>
      <title>Kafka Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-02-15-kafka-cluster/</link>
      <pubDate>Fri, 15 Feb 2019 13:42:46 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-02-15-kafka-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &#39;2.1&#39; services: zoo1: image: zookeeper:3.4.9 hostname: zoo1 ports: - &amp;quot;2181:2181&amp;quot; container_name: docker_zoo_1 environment: ZOO_MY_ID: 1 ZOO_PORT: 2181 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper:3.4.9 hostname: zoo2 ports: - &amp;quot;2182:2182&amp;quot; container_name: docker_zoo_2 environment: ZOO_MY_ID: 2 ZOO_PORT: 2182 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper:3.4.9 hostname: zoo3 ports: - &amp;quot;2183:2183&amp;quot; container_name: docker_zoo_3 environment: ZOO_MY_ID: 3 ZOO_PORT: 2183 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 kafka1: image: confluentinc/cp-kafka:5.0.0 hostname: kafka1 ports: - &amp;quot;9092:9092&amp;quot; container_name: docker_kafka_1 environment: KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-192.</description>
    </item>
    
    <item>
      <title>Cassandra Cluster Docker Compose Yaml</title>
      <link>https://mason-ko.github.io/posts/tech/2019/2019-01-21-cassandra-cluster/</link>
      <pubDate>Mon, 21 Jan 2019 11:00:00 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2019/2019-01-21-cassandra-cluster/</guid>
      <description>Docker Compose File docker-compose.yaml
version: &#39;2&#39; services: cassandra1: image: cassandra ports: - 7000:7000 - 7001:7001 - 9160:9160 - 9042:9042 environment: CASSANDRA_BROADCAST_ADDRESS: &amp;quot;10.5.0.10&amp;quot; CASSANDRA_SEEDS: &amp;quot;10.5.0.10&amp;quot; CASSANDRA_CLUSTER_NAME: &amp;quot;Test Cluster&amp;quot; CASSANDRA_DC: &amp;quot;DC1&amp;quot; CASSANDRA_RACK: &amp;quot;RAC1&amp;quot; CASSANDRA_ENDPOINT_SNITCH: &amp;quot;GossipingPropertyFileSnitch&amp;quot; CASSANDRA_START_RPC: &amp;quot;true&amp;quot; hostname: cassandra1 container_name: docker_cassandra_1 logging: driver: json-file options: max-size: 50m networks: cassnw: ipv4_address: 10.5.0.10 cassandra2: image: cassandra environment: CASSANDRA_BROADCAST_ADDRESS: &amp;quot;10.5.0.10&amp;quot; CASSANDRA_SEEDS: &amp;quot;10.5.0.10&amp;quot; CASSANDRA_CLUSTER_NAME: &amp;quot;Test Cluster&amp;quot; CASSANDRA_DC: &amp;quot;DC1&amp;quot; CASSANDRA_RACK: &amp;quot;RAC1&amp;quot; CASSANDRA_ENDPOINT_SNITCH: &amp;quot;GossipingPropertyFileSnitch&amp;quot; CASSANDRA_START_RPC: &amp;quot;true&amp;quot; hostname: cassandra2 container_name: docker_cassandra_2 logging: driver: json-file options: max-size: 50m networks: cassnw: ipv4_address: 10.</description>
    </item>
    
    <item>
      <title>Redis Replication Docker로 설치</title>
      <link>https://mason-ko.github.io/posts/tech/2018/2018-12-28-redis-replication-on-docker/</link>
      <pubDate>Fri, 28 Dec 2018 16:42:46 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2018/2018-12-28-redis-replication-on-docker/</guid>
      <description>Install Environment CentOs 7 방화벽 해제 sudo systemctl stop firewalld sudo systemctl disable firewalld sudo setenforce 0 Install Docker &amp;amp; Docker Compose yum install -y docker sudo curl -L &amp;quot;https://github.com/docker/compose/releases/download/1.23.1/docker-compose-$(uname -s)-$(uname -m)&amp;quot; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Redis Replication Config File 준비  redis.conf 만듬 Redis Stable Config 복사 protected-mode 사용중일 때 비밀번호 필요하며 Docker 외부에서 사용가능하도록 bind 주석 처리 각 slave config에 master 정보 추가  mkdir ./s1 .</description>
    </item>
    
    <item>
      <title>Redis Sentinel Docker로 설치</title>
      <link>https://mason-ko.github.io/posts/tech/2018/2018-12-28-redis-sentinel-on-docker/</link>
      <pubDate>Fri, 28 Dec 2018 16:42:46 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2018/2018-12-28-redis-sentinel-on-docker/</guid>
      <description>Install Environment CentOs 7 방화벽 해제 sudo systemctl stop firewalld sudo systemctl disable firewalld sudo setenforce 0 Install Docker &amp;amp; Docker Compose yum install -y docker sudo curl -L &amp;quot;https://github.com/docker/compose/releases/download/1.23.1/docker-compose-$(uname -s)-$(uname -m)&amp;quot; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Redis Sentinel Config File 준비 sentinel.conf 만듬
mkdir ./sentinel1 ./sentinel2 ./sentinel3 echo &#39;sentinel monitor mymaster 10.0.0.1 7000 2&#39; &amp;gt;&amp;gt; sentinel.conf echo &#39;sentinel down-after-milliseconds mymaster 5000&#39; &amp;gt;&amp;gt; sentinel.conf echo &#39;sentinel failover-timeout mymaster 7000&#39; &amp;gt;&amp;gt; sentinel.</description>
    </item>
    
    <item>
      <title>Ambrai 설치</title>
      <link>https://mason-ko.github.io/posts/tech/2018/2018-12-07-abmari-install/</link>
      <pubDate>Fri, 07 Dec 2018 11:08:46 +0900</pubDate>
      
      <guid>https://mason-ko.github.io/posts/tech/2018/2018-12-07-abmari-install/</guid>
      <description>Install Environment Windows 10 VM 환경 공통  os : centos 7.5.1804  IP  server : 192.168.56.103 agent : 192.168.56.104  방화벽 해제 sudo systemctl stop firewalld sudo systemctl disable firewalld sudo setenforce 0 Host Name 등록 Server
sudo hostnamectl set-hostname server1.kr Agent
sudo hostnamectl set-hostname agent1.kr Install Java sudo yum install -y java-1.8.0-openjdk wget Install Ambrai Server sudo wget -nv http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.2.2/ambari.repo -O /etc/yum.repos.d/ambari.repo sudo yum install -y ambari-server Set FQDN Server와 Agent의 Host 설정</description>
    </item>
    
  </channel>
</rss>
